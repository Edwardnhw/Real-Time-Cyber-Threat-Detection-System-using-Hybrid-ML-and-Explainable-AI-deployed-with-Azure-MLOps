{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# MLflow-Based Batch Deployment on Azure Machine Learning\n",
        "\n",
        "This notebook demonstrates how to deploy and run MLflow-logged models using Azure Machine Learning's **batch endpoints**.\n",
        "\n",
        "By leveraging **MLflow tracking** and **no-code deployment capabilities**, you can streamline the deployment process without the need to manually define a scoring script or custom environment.\n",
        "\n",
        "### Key Features of No-Code Batch Deployment:\n",
        "- Automatically uses a curated Azure ML environment with all necessary MLflow dependencies pre-installed.\n",
        "- Generates an internal scoring script and batch scoring pipeline behind the scenes.\n",
        "- Simplifies deployment by referencing a previously registered MLflow model artifact.\n",
        "- Supports large-scale parallel processing of input data with batch endpoints.\n",
        "\n",
        "This approach is ideal for:\n",
        "- Rapidly operationalizing MLflow models.\n",
        "- Running inference asynchronously on large datasets.\n",
        "- Integrating batch prediction seamlessly into production MLOps pipelines.\n",
        "\n",
        "In the following steps, you'll configure the deployment, define batch input/output, and submit a batch job without writing custom scoring logic.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Connect to Azure Machine Learning Workspace\n",
        "\n",
        "This section initiates the setup required to enable batch inference with MLflow-logged models. The Azure Machine Learning workspace serves as the centralized resource for managing experiments, models, data, and compute targets. \n",
        "\n",
        "Establishing a connection to the workspace ensures access to previously registered assets and provides the foundation for executing batch deployments programmatically.\n",
        "\n",
        "### 1.1. Import required libraries\n",
        "\n",
        "The necessary modules from the Azure ML SDK v2 are imported to support batch endpoint creation, model deployment, compute resource configuration, and interaction with registered assets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from azure.ai.ml import MLClient, Input\n",
        "from azure.ai.ml.entities import (\n",
        "    BatchEndpoint,\n",
        "    ModelBatchDeployment,\n",
        "    ModelBatchDeploymentSettings,\n",
        "    Model,\n",
        "    AmlCompute,\n",
        "    Data,\n",
        "    BatchRetrySettings,\n",
        "    CodeConfiguration,\n",
        "    Environment,\n",
        ")\n",
        "from azure.ai.ml.constants import AssetTypes, BatchDeploymentOutputAction\n",
        "from azure.identity import DefaultAzureCredential"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2. Configure workspace details and initialize MLClient\n",
        "\n",
        "To interact with Azure Machine Learning programmatically, a connection to the workspace must be established using subscription ID, resource group, and workspace name. These identifiers are passed to the `MLClient` to authenticate and manage resources within the target environment.\n",
        "\n",
        "This notebook uses `DefaultAzureCredential` to handle authentication, which simplifies credential management by supporting multiple authentication mechanisms. This method is well-suited for local development as well as cloud-hosted environments.\n",
        "\n",
        "The client object created here is essential for performing operations such as model registration, deployment, and job submission throughout the batch inference workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "subscription_id = \"43dae9af-3755-421b-bfae-29b91f9e85dd\"\n",
        "resource_group = \"cyberml-canada-rg\"\n",
        "workspace = \"cyberml-ws\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "ml_client = MLClient(\n",
        "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If a Azure Machine Learning compute is used:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: /config.json\n"
          ]
        }
      ],
      "source": [
        "ml_client = MLClient.from_config(DefaultAzureCredential())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 2. Registering the Model\n",
        "\n",
        "### 2.1 Model Overview\n",
        "\n",
        "This project leverages a machine learning model designed to detect potential cybersecurity intrusions. Unlike the default example which references heart disease detection, this implementation focuses on identifying malicious activity using features derived from network traffic and system behavior logs.\n",
        "\n",
        "The model is structured as an MLflow model pipeline and includes preprocessing and classification components. This allows raw input data to be directly passed through the model for inference, simplifying deployment and ensuring reproducibility.\n",
        "\n",
        "### 2.2 Model Registration in Azure ML\n",
        "\n",
        "To make the model available for batch inference deployment, it must be registered in the Azure Machine Learning model registry. The script checks if the `cyber_intrusion_model` is already available; if not, it registers the MLflow-packaged model located in the specified directory.\n",
        "\n",
        "Registering the model ensures version control and enables tracking across environments and endpoints.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "name": "register_model",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mUploading cyber_intrusion_model_ (0.88 MBs): 100%|██████████| 878601/878601 [00:00<00:00, 14243109.38it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model_name = \"cyber_intrusion_model\"\n",
        "model_local_path = \"/home/azureuser/cloudfiles/code/cyber_intrusion_model_\"\n",
        "\n",
        "model = ml_client.models.create_or_update(\n",
        "    Model(name=model_name, path=model_local_path, type=AssetTypes.MLFLOW_MODEL)\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Let's get the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "name": "get_model",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "model_name = \"cyber_intrusion_model\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## 3. Creating a Batch Endpoint\n",
        "\n",
        "Batch endpoints facilitate asynchronous, large-scale inference tasks in Azure Machine Learning. They are particularly effective for scenarios involving high-volume data processing, such as analyzing network traffic or system logs for cybersecurity threats.\n",
        "\n",
        "A batch endpoint enables decoupling of model scoring from real-time requirements by accepting pointers to data stored in blob storage or datastores. Jobs triggered on the endpoint are executed on compute clusters and results are written back to storage for downstream tasks such as reporting or auditing.\n",
        "\n",
        "### 3.1 Endpoint Configuration\n",
        "\n",
        "This section configures a batch endpoint intended to host a model deployment for cybersecurity intrusion detection. To ensure global uniqueness within the Azure region, the endpoint name is appended with a random suffix. While this approach helps prevent naming conflicts in test environments, meaningful naming conventions are typically used in production for better traceability.\n",
        "\n",
        "The `BatchEndpoint` configuration includes:\n",
        "- `name`: A unique identifier for the endpoint.\n",
        "- `description`: A textual summary of the endpoint’s purpose.\n",
        "- `auth_mode`: Default authentication mode is Azure Active Directory token-based access.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "name": "name_endpoint"
      },
      "outputs": [],
      "source": [
        "endpoint_name = \"batch-cyber-intrusion\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Endpoint name: batch-cyber-intrusion-so9ut\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import string\n",
        "\n",
        "# Creating a unique endpoint name by including a random suffix\n",
        "allowed_chars = string.ascii_lowercase + string.digits\n",
        "endpoint_suffix = \"\".join(random.choice(allowed_chars) for x in range(5))\n",
        "endpoint_name = f\"{endpoint_name}-{endpoint_suffix}\"\n",
        "\n",
        "print(f\"Endpoint name: {endpoint_name}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To configure the endpoint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "name": "configure_endpoint"
      },
      "outputs": [],
      "source": [
        "endpoint = BatchEndpoint(\n",
        "    name=endpoint_name,\n",
        "    description=\"A cyber intrusion condition classifier for batch inference\",\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Creating the Endpoint\n",
        "\n",
        "This step initiates the creation of the batch endpoint within the Azure Machine Learning workspace. The previously configured `MLClient` instance is used to submit the endpoint definition to the Azure backend.\n",
        "\n",
        "Once submitted, the operation proceeds asynchronously but returns a confirmation object immediately. This allows batch scoring jobs to be routed through a consistent endpoint interface that abstracts underlying infrastructure details.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "name": "create_endpoint",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BatchEndpoint({'scoring_uri': 'https://batch-cyber-intrusion-so9ut.canadacentral.inference.ml.azure.com/jobs', 'openapi_uri': None, 'provisioning_state': 'Succeeded', 'name': 'batch-cyber-intrusion-so9ut', 'description': 'A cyber intrusion condition classifier for batch inference', 'tags': {}, 'properties': {'BatchEndpointCreationApiVersion': '2023-10-01', 'azureml.onlineendpointid': '/subscriptions/43dae9af-3755-421b-bfae-29b91f9e85dd/resourceGroups/cyberml-canada-rg/providers/Microsoft.MachineLearningServices/workspaces/cyberml-ws/batchEndpoints/batch-cyber-intrusion-so9ut'}, 'print_as_yaml': False, 'id': '/subscriptions/43dae9af-3755-421b-bfae-29b91f9e85dd/resourceGroups/cyberml-canada-rg/providers/Microsoft.MachineLearningServices/workspaces/cyberml-ws/batchEndpoints/batch-cyber-intrusion-so9ut', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpucluster01/code', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fc1ea01ad70>, 'auth_mode': 'aad_token', 'location': 'canadacentral', 'defaults': <azure.ai.ml._restclient.v2023_10_01.models._models_py3.BatchEndpointDefaults object at 0x7fc1dc59e170>})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.batch_endpoints.begin_create_or_update(endpoint).result()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Create a batch deployment\n",
        "\n",
        "A deployment is a set of resources required for hosting the model that does the actual inferencing. A deployment for the endpoint using the `BatchDeployment` class will be created as below.\n",
        "\n",
        "### 4.1 Creating an scoring script to work with the model\n",
        "\n",
        "> MLflow models don't require an scoring script."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 4.2 Creating the Compute\n",
        "\n",
        "Batch deployments in Azure Machine Learning require compute resources capable of handling large-scale data processing workloads. These deployments can leverage any available compute cluster within the workspace, supporting scalability and reusability across multiple jobs.\n",
        "\n",
        "This step ensures the existence of an AzureML compute cluster suitable for batch operations. If the specified cluster is not found in the workspace, it is created with a defined scale range, enabling dynamic provisioning based on job demand.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "name": "create_compute",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "compute_name = \"batch-cluster\"\n",
        "if not any(filter(lambda m: m.name == compute_name, ml_client.compute.list())):\n",
        "    compute_cluster = AmlCompute(\n",
        "        name=compute_name, description=\"amlcompute\", min_instances=0, max_instances=5\n",
        "    )\n",
        "    ml_client.begin_create_or_update(compute_cluster).result()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Creating the environment\n",
        "\n",
        "> MLflow models don't require an environment."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 4.4 Configuring the deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "name": "configure_deployment",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "deployment = ModelBatchDeployment(\n",
        "    name=\"cyber-intrusion-deployment\",\n",
        "    description=\"A cyber intrusion condition classifier for batch inference\",\n",
        "    endpoint_name=endpoint.name,\n",
        "    model=model,\n",
        "    compute=compute_name,\n",
        "    settings=ModelBatchDeploymentSettings(\n",
        "        instance_count=1,\n",
        "        max_concurrency_per_instance=1,\n",
        "        mini_batch_size=10,\n",
        "        output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
        "        output_file_name=\"predictions.csv\",\n",
        "        retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n",
        "        logging_level=\"info\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5 Create the deployment\n",
        "Using the `MLClient` created earlier, the deployment in the workspace should be created next. This command will start the deployment creation and return a confirmation response while the deployment creation continues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "name": "create_deployment",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BatchDeployment({'provisioning_state': 'Succeeded', 'endpoint_name': 'batch-cyber-intrusion-so9ut', 'type': None, 'name': 'cyber-intrusion-deployment', 'description': 'A cyber intrusion condition classifier for batch inference', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/43dae9af-3755-421b-bfae-29b91f9e85dd/resourceGroups/cyberml-canada-rg/providers/Microsoft.MachineLearningServices/workspaces/cyberml-ws/batchEndpoints/batch-cyber-intrusion-so9ut/deployments/cyber-intrusion-deployment', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpucluster01/code', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fc1d94400a0>, 'serialize': <msrest.serialization.Serializer object at 0x7fc1d9443010>, 'model': '/subscriptions/43dae9af-3755-421b-bfae-29b91f9e85dd/resourceGroups/cyberml-canada-rg/providers/Microsoft.MachineLearningServices/workspaces/cyberml-ws/models/cyber_intrusion_model/versions/13', 'code_configuration': None, 'environment': None, 'environment_variables': {}, 'compute': '/subscriptions/43dae9af-3755-421b-bfae-29b91f9e85dd/resourceGroups/cyberml-canada-rg/providers/Microsoft.MachineLearningServices/workspaces/cyberml-ws/computes/batch-cluster', 'resources': {'instance_count': 1, 'properties': {}}, 'output_action': 'append_row', 'output_file_name': 'predictions.csv', 'error_threshold': -1, 'retry_settings': <azure.ai.ml.entities._deployment.deployment_settings.BatchRetrySettings object at 0x7fc1d9441120>, 'logging_level': 'Info', 'mini_batch_size': 10, 'max_concurrency_per_instance': 1})"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.batch_deployments.begin_create_or_update(deployment).result()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Once created, to configure this new deployment as the default one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "name": "set_default_deployment",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BatchEndpoint({'scoring_uri': 'https://batch-cyber-intrusion-so9ut.canadacentral.inference.ml.azure.com/jobs', 'openapi_uri': None, 'provisioning_state': 'Succeeded', 'name': 'batch-cyber-intrusion-so9ut', 'description': 'A cyber intrusion condition classifier for batch inference', 'tags': {}, 'properties': {'BatchEndpointCreationApiVersion': '2023-10-01', 'azureml.onlineendpointid': '/subscriptions/43dae9af-3755-421b-bfae-29b91f9e85dd/resourceGroups/cyberml-canada-rg/providers/Microsoft.MachineLearningServices/workspaces/cyberml-ws/batchEndpoints/batch-cyber-intrusion-so9ut'}, 'print_as_yaml': False, 'id': '/subscriptions/43dae9af-3755-421b-bfae-29b91f9e85dd/resourceGroups/cyberml-canada-rg/providers/Microsoft.MachineLearningServices/workspaces/cyberml-ws/batchEndpoints/batch-cyber-intrusion-so9ut', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpucluster01/code', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fc1bb963730>, 'auth_mode': 'aad_token', 'location': 'canadacentral', 'defaults': <azure.ai.ml._restclient.v2023_10_01.models._models_py3.BatchEndpointDefaults object at 0x7fc1bb963be0>})"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "endpoint = ml_client.batch_endpoints.get(endpoint.name)\n",
        "endpoint.defaults.deployment_name = deployment.name\n",
        "ml_client.batch_endpoints.begin_create_or_update(endpoint).result()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The default deployment is cyber-intrusion-deployment\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(f\"The default deployment is {endpoint.defaults.deployment_name}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### 4.6 Testing the deployment\n",
        "\n",
        "Once the deployment is created, it is ready to recieve jobs.\n",
        "\n",
        "#### 4.6.1 Creating a data asset\n",
        "\n",
        "This data asset is a file containing randomized entries from the original cyber intrusion dataset. We are going to download it first and then create the data asset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "name": "configure_data_asset",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "data_path = \"/home/azureuser/cloudfiles/code/Users/edwardhw.ng/cybersecurity_intrusion_data_test.csv\"\n",
        "dataset_name = \"cybersecurity_intrusion_data_test\"\n",
        "\n",
        "cyber_dataset_unlabeled = Data(\n",
        "    path=data_path,\n",
        "    type=AssetTypes.URI_FILE,\n",
        "    description=\"An unlabeled dataset for cyber intrusion classification\",\n",
        "    name=dataset_name,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "name": "create_data_asset"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Uploading cybersecurity_intrusion_data_test.csv (< 1 MB): 0.00B [00:00, ?B/s]Uploading cybersecurity_intrusion_data_test.csv (< 1 MB): 0.00B [00:00, ?B/s] (< 1 MB): 100%|██████████| 122k/122k [00:00<00:00, 4.45MB/s] (< 1 MB): 100%|██████████| 122k/122k [00:00<00:00, 4.45MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Data({'path': 'azureml://subscriptions/43dae9af-3755-421b-bfae-29b91f9e85dd/resourcegroups/cyberml-canada-rg/workspaces/cyberml-ws/datastores/workspaceblobstore/paths/LocalUpload/31f972944d728493651c169991abece5/cybersecurity_intrusion_data_test.csv', 'skip_validation': False, 'mltable_schema_url': None, 'referenced_uris': None, 'type': 'uri_file', 'is_anonymous': False, 'auto_increment_version': False, 'auto_delete_setting': None, 'name': 'cybersecurity_intrusion_data_test', 'description': 'An unlabeled dataset for intrusion classification', 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/43dae9af-3755-421b-bfae-29b91f9e85dd/resourceGroups/cyberml-canada-rg/providers/Microsoft.MachineLearningServices/workspaces/cyberml-ws/data/cybersecurity_intrusion_data_test/versions/1', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpucluster01/code', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fc1d82bfd00>, 'serialize': <msrest.serialization.Serializer object at 0x7fc1bbe180d0>, 'version': '1', 'latest_version': None, 'datastore': None})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.data.create_or_update(cyber_dataset_unlabeled)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To get a reference of the new data asset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "name": "get_data_asset",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "cyber_dataset_unlabeled = ml_client.data.get(name=dataset_name, label=\"latest\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### 4.6.2 Creating an input for the deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "name": "configure_inputs",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "input = Input(type=AssetTypes.URI_FILE, path=cyber_dataset_unlabeled.id)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.6.3 Invoke the deployment\n",
        "\n",
        "Using the `MLClient` created earlier, the endpoint can be invoked using the `invoke` command with the following parameters:\n",
        "- `name` - Name of the endpoint\n",
        "- `input_path` - Path where input data is present"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "name": "start_batch_scoring_job",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "job = ml_client.batch_endpoints.invoke(endpoint_name=endpoint.name, input=input)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Since the endpoint only has one deployment, then that one is the default one. Notes: an specific deployment can also be targetted, by indicating the argument/parameter `deployment_name`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "job = ml_client.batch_endpoints.invoke(\n",
        "    deployment_name=deployment.name, endpoint_name=endpoint.name, input=input\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### 4.6.4 Get the details of the invoked job\n",
        "\n",
        "Let us get details and logs of the invoked job:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "name": "get_job",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>batch-cyber-intrusion-so9ut</td><td>batchjob-a466a77d-6e62-4ff8-be1d-c39bce7ede6f</td><td>pipeline</td><td>Running</td><td><a href=\"https://ml.azure.com/runs/batchjob-a466a77d-6e62-4ff8-be1d-c39bce7ede6f?wsid=/subscriptions/43dae9af-3755-421b-bfae-29b91f9e85dd/resourcegroups/cyberml-canada-rg/workspaces/cyberml-ws&amp;tid=78aac226-2f03-4b4d-9037-b46d56c55210\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
            ],
            "text/plain": [
              "PipelineJob({'inputs': {}, 'outputs': {}, 'jobs': {}, 'component': PipelineComponent({'latest_version': None, 'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'auto_delete_setting': None, 'name': 'azureml_anonymous', 'description': \"Attempting to create pipeline submission settings for endpoint: 'batch-cyber-intrusion-so9ut', deployment: 'cyber-intrusion-deployment'.\", 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': None, 'Resource__source_path': None, 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpucluster01/code', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x7fc1bbbd7460>, 'version': '1', 'schema': None, 'type': 'pipeline', 'display_name': 'cool_rainbow_jkt99kbh', 'is_deterministic': None, 'inputs': {}, 'outputs': {}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {}, 'job_types': {}, 'job_sources': {}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'Running', 'log_files': None, 'name': 'batchjob-a466a77d-6e62-4ff8-be1d-c39bce7ede6f', 'description': \"Attempting to create pipeline submission settings for endpoint: 'batch-cyber-intrusion-so9ut', deployment: 'cyber-intrusion-deployment'.\", 'tags': {'outputType': 'output_data', 'output_data_name': None, 'inputType': 'input_data', 'azureml.batchrun': 'true', 'azureml.deploymentname': 'cyber-intrusion-deployment', 'azureml.jobtype': 'azureml.batchjob'}, 'properties': {'azureml.deploymentname': 'cyber-intrusion-deployment', 'azureml.endpointname': 'batch-cyber-intrusion-so9ut', 'azureml.pipelineid': '8f44b548-5df1-4a76-8fcf-4336ac895c03', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{\"run_max_try\":\"3\",\"run_invocation_timeout\":\"300\",\"mini_batch_size\":\"10\",\"error_threshold\":\"-1\",\"logging_level\":\"INFO\",\"process_count_per_node\":\"1\",\"NodeCount\":\"1\",\"append_row_file_name\":\"predictions.csv\"}', 'azureml.continue_on_step_failure': 'False', 'azureml.continue_on_failed_optional_input': 'False', 'azureml.pipelineComponent': 'pipelinerun'}, 'print_as_yaml': False, 'id': '/subscriptions/43dae9af-3755-421b-bfae-29b91f9e85dd/resourceGroups/cyberml-canada-rg/providers/Microsoft.MachineLearningServices/workspaces/cyberml-ws/jobs/batchjob-a466a77d-6e62-4ff8-be1d-c39bce7ede6f', 'Resource__source_path': '', 'base_path': '/mnt/batch/tasks/shared/LS_root/mounts/clusters/cpucluster01/code', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x7fc1d94401f0>, 'serialize': <msrest.serialization.Serializer object at 0x7fc1bb9624a0>, 'display_name': 'cool_rainbow_jkt99kbh', 'experiment_name': 'batch-cyber-intrusion-so9ut', 'compute': None, 'services': {'Tracking': {'endpoint': 'azureml://canadacentral.api.azureml.ms/mlflow/v1.0/subscriptions/43dae9af-3755-421b-bfae-29b91f9e85dd/resourceGroups/cyberml-canada-rg/providers/Microsoft.MachineLearningServices/workspaces/cyberml-ws?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/batchjob-a466a77d-6e62-4ff8-be1d-c39bce7ede6f?wsid=/subscriptions/43dae9af-3755-421b-bfae-29b91f9e85dd/resourcegroups/cyberml-canada-rg/workspaces/cyberml-ws&tid=78aac226-2f03-4b4d-9037-b46d56c55210', 'type': 'Studio'}}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ml_client.jobs.get(job.name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can wait for the job to finish using the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "name": "stream_job_logs"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'job' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ml_client\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mstream(\u001b[43mjob\u001b[49m\u001b[38;5;241m.\u001b[39mname)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'job' is not defined"
          ]
        }
      ],
      "source": [
        "ml_client.jobs.stream(job.name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.7 Exploring the results\n",
        "\n",
        "The deployment creates a child job that executes the scoring."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'ml_client' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scoring_job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mml_client\u001b[49m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mlist(parent_job_name\u001b[38;5;241m=\u001b[39mjob\u001b[38;5;241m.\u001b[39mname))[\u001b[38;5;241m0\u001b[39m]\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ml_client' is not defined"
          ]
        }
      ],
      "source": [
        "scoring_job = list(ml_client.jobs.list(parent_job_name=job.name))[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Job name:\", scoring_job.name)\n",
        "print(\"Job status:\", scoring_job.status)\n",
        "print(\n",
        "    \"Job duration:\",\n",
        "    scoring_job.creation_context.last_modified_at\n",
        "    - scoring_job.creation_context.created_at,\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.7.1 Download the results\n",
        "\n",
        "The outputs generated by the deployment job will be placed in an output named `score`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "name": "download_outputs"
      },
      "outputs": [],
      "source": [
        "ml_client.jobs.download(name=scoring_job.name, download_path=\".\", output_name=\"score\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "name": "read_outputs",
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "score = pd.read_csv(\n",
        "    \"named-outputs/score/predictions.csv\", names=[\"row\", \"prediction\", \"file\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.7.2 Logging Predictions for Auditability\n",
        "\n",
        "With the batch endpoint live and scoring logic in place, a batch scoring job was submitted to generate predictions on new input data.\n",
        "\n",
        "#### Batch Job Submission\n",
        "\n",
        "The job was configured to:\n",
        "- Use a previously uploaded file (`cyber_intrusion.csv`) from the workspace blob store as input  \n",
        "- Mount the input file in read-only mode for performance and safety  \n",
        "- Define the output as a `URI_FILE`, storing predictions as a single `.csv` file in a designated output path within the blob store  \n",
        "\n",
        "Upon submission, Azure ML handled the job asynchronously—spinning up compute, running inference, and writing the results to the specified output location.\n",
        "\n",
        "#### Why This Matters for Auditability\n",
        "\n",
        "Logging predictions is a critical step for ensuring:\n",
        "- **Traceability**: All outputs are stored with timestamps and paths that can be referenced later  \n",
        "- **Reproducibility**: Given the same input data and model version, the predictions can be regenerated  \n",
        "- **Transparency**: Outputs can be inspected manually or automatically to verify model behavior  \n",
        "- **Compliance**: Especially in regulated domains like cybersecurity, maintaining a clear record of predictions supports operational accountability\n",
        "\n",
        "This logged prediction output will also serve as input for the next steps—evaluating model performance and setting up drift detection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: /config.json\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Latest Batch Job ID: batchjob-f42d7086-b47a-419f-a06f-2b292fef07e5\n",
            "Status         : Completed\n",
            "Start Time     : 2025-04-06 04:12:13.733869+00:00\n",
            "Compute Target : None\n",
            "\n",
            " Batch job info logged to 'batch_job_audit_log.txt'\n"
          ]
        }
      ],
      "source": [
        "# Logging Predictions for Auditability\n",
        "\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.identity import DefaultAzureCredential\n",
        "from datetime import datetime\n",
        "\n",
        "# Initialize ML client\n",
        "ml_client = MLClient.from_config(credential=DefaultAzureCredential())\n",
        "\n",
        "# Optional: your endpoint name\n",
        "batch_endpoint_name = \"batch-cyber-intrusion\"\n",
        "\n",
        "# List all jobs in the workspace\n",
        "all_jobs = list(ml_client.jobs.list())\n",
        "\n",
        "# Filter for jobs likely related to batch inference\n",
        "batch_jobs = [\n",
        "    job for job in all_jobs\n",
        "    if \"batch\" in job.name.lower() or \"cyber\" in job.name.lower()\n",
        "]\n",
        "\n",
        "# Safety check\n",
        "if not batch_jobs:\n",
        "    print(\"⚠️ No recent batch jobs found. Try submitting again or wait a few minutes.\")\n",
        "else:\n",
        "    # Get the most recent job\n",
        "    latest_job = sorted(\n",
        "        batch_jobs,\n",
        "        key=lambda x: x.creation_context.created_at,\n",
        "        reverse=True\n",
        "    )[0]\n",
        "\n",
        "    # Log job details\n",
        "    print(f\"Latest Batch Job ID: {latest_job.name}\")\n",
        "    print(f\"Status         : {latest_job.status}\")\n",
        "    print(f\"Start Time     : {latest_job.creation_context.created_at}\")\n",
        "    print(f\"Compute Target : {latest_job.compute}\")\n",
        "    \n",
        "    # Save job info to audit log file\n",
        "    output_path = \"/home/azureuser/cloudfiles/code/Users/edwardhw.ng/named-outputs/score\"\n",
        "    log_entry = f\"\"\"Job Run: {datetime.now()}\n",
        "- ID: {latest_job.name}\n",
        "- Status: {latest_job.status}\n",
        "- Compute: {latest_job.compute}\n",
        "- Output Path: {output_path}\n",
        "- Studio URI: {latest_job.services.get('Studio', {}).get('endpoint', 'Not Available') if latest_job.services else 'N/A'}\n",
        "\n",
        "-------------------------\n",
        "\"\"\"\n",
        "\n",
        "    with open(\"batch_job_audit_log.txt\", \"a\") as log_file:\n",
        "        log_file.write(log_entry)\n",
        "\n",
        "    print(\"\\n Batch job info logged to 'batch_job_audit_log.txt'\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Customize deployment with an scoring script\n",
        "\n",
        "An customized scoring script with MLflow models in batch endpoints can be used also:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Create an scoring script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile code/batch_driver.py\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import mlflow\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "    global model_input_types\n",
        "    global model_output_names\n",
        "\n",
        "    # AZUREML_MODEL_DIR is an environment variable created during deployment, which is the path to the model folder\n",
        "    model_path = glob.glob(os.environ[\"AZUREML_MODEL_DIR\"] + \"/*/\")[0]\n",
        "\n",
        "    # Load the model, it's input types and output names\n",
        "    model = mlflow.pyfunc.load(model_path)\n",
        "    if model.metadata.signature.inputs:\n",
        "        model_input_types = dict(\n",
        "            zip(\n",
        "                model.metadata.signature.inputs.input_names(),\n",
        "                model.metadata.signature.inputs.pandas_types(),\n",
        "            )\n",
        "        )\n",
        "    if model.metadata.signature.outputs:\n",
        "        if model.metadata.signature.outputs.has_input_names():\n",
        "            model_output_names = model.metadata.signature.outputs.input_names()\n",
        "        elif len(model.metadata.signature.outputs.input_names()) == 1:\n",
        "            model_output_names = [\"prediction\"]\n",
        "\n",
        "\n",
        "def run(mini_batch):\n",
        "    print(f\"run method start: {__file__}, run({len(mini_batch)} files)\")\n",
        "\n",
        "    data = pd.concat(\n",
        "        map(\n",
        "            lambda fp: pd.read_csv(fp).assign(filename=os.path.basename(fp)), mini_batch\n",
        "        )\n",
        "    )\n",
        "    if model_input_types:\n",
        "        data = data.astype(model_input_types)\n",
        "\n",
        "    pred = model.predict(data)\n",
        "\n",
        "    if pred is not pd.DataFrame:\n",
        "        if not model_output_names:\n",
        "            model_output_names = [\"pred_col\" + str(i) for i in range(pred.shape[1])]\n",
        "        pred = pd.DataFrame(pred, columns=model_output_names)\n",
        "\n",
        "    return pd.concat([data, pred], axis=1)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Indicate the environment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "name": "configure_environment_custom"
      },
      "outputs": [],
      "source": [
        "environment = Environment(\n",
        "    name=\"batch-mlflow-environment\",\n",
        "    conda_file=\"environment/conda.yaml\",\n",
        "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Configure the deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "name": "configure_deployment_custom"
      },
      "outputs": [],
      "source": [
        "deployment = ModelBatchDeployment(\n",
        "    name=\"classifier-cyber-custom\",\n",
        "    description=\"A cyber intrusion classifier with a custom scoring script\",\n",
        "    endpoint_name=endpoint.name,\n",
        "    model=model,\n",
        "    environment=environment,\n",
        "    code_configuration=CodeConfiguration(code=\"code\", scoring_script=\"batch_driver.py\"),\n",
        "    compute=compute_name,\n",
        "    settings=ModelBatchDeploymentSettings(\n",
        "        instance_count=2,\n",
        "        max_concurrency_per_instance=2,\n",
        "        mini_batch_size=10,\n",
        "        output_action=BatchDeploymentOutputAction.APPEND_ROW,\n",
        "        output_file_name=\"predictions.csv\",\n",
        "        retry_settings=BatchRetrySettings(max_retries=3, timeout=300),\n",
        "        logging_level=\"info\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Create the deployment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "name": "create_deployment_custom"
      },
      "outputs": [],
      "source": [
        "ml_client.batch_deployments.begin_create_or_update(deployment).result()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Clean up resources\n",
        "\n",
        "Clean-up the resources created. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "name": "delete_endpoint"
      },
      "outputs": [],
      "source": [
        "ml_client.batch_endpoints.begin_delete(endpoint_name).result()"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
